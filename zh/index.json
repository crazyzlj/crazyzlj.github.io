[{"authors":null,"categories":null,"content":"","date":1538236800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"d41004924d2f409fa91be203ee601bd6","permalink":"http://zhulj.net/zh/project/2014-phd-dissertation/","publishdate":"2018-09-30T00:00:00+08:00","relpermalink":"/zh/project/2014-phd-dissertation/","section":"project","summary":"","tags":["Watershed modeling and scenario analysis","GeoComputation"],"title":"博士论文","type":"project"},{"authors":null,"categories":null,"content":"","date":1538236800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"dcf1a5f86dd6d091616dd229774c0441","permalink":"http://zhulj.net/zh/project/2011-msc-thesis/","publishdate":"2018-09-30T00:00:00+08:00","relpermalink":"/zh/project/2011-msc-thesis/","section":"project","summary":"","tags":["Experiments"],"title":"硕士论文","type":"project"},{"authors":["秦承志","高会然","\u003cb\u003e\u003cI\u003e朱良君*\u003c/I\u003e\u003c/b\u003e","朱阿兴","刘军志","吴辉"],"categories":null,"content":"","date":1535731200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538318158,"objectID":"1cee7253d290d507b9e44deb43bbc7aa","permalink":"http://zhulj.net/zh/publication/2018-jswc-bmpsoptslppos/","publishdate":"2018-09-01T00:00:00+08:00","relpermalink":"/zh/publication/2018-jswc-bmpsoptslppos/","section":"publication","summary":"基于流域过程模拟的管理措施（BMPs）情景分析与优化是当前对流域管理措施实施效果进行预先评价的重要途径。现有方法通常采用地块、农场、水文响应单元或子流域作为BMPs空间配置单元，这些空间配置单元难以有效地根据坡面自然过程来表达坡面上不同BMPs之间的空间配置关系，因此也难以应用相应的领域知识，将直接影响流域BMP情景空间优化的效果。针对以上问题，提出以坡位（如山脊、背坡、沟谷等）作为BMPs空间配置单元，在空间全分布式流域过程模拟和BMPs情景智能优化的方法框架基础上，建立了一套以坡位为空间配置单元的流域BMPs情景优化方法，可有效体现BMPs空间配置关系、应用相应的BMP空间配置关系知识。在南方红壤区福建长汀县游屋圳小流域的应用案例表明，与随机配置方法相比，新方法能够根据坡面过程特点进行BMPs情景优化，有效地获得更为实际可行的管理措施空间配置优化方案。","tags":["坡位","空间优化","BMPs"],"title":"Spatial optimization of watershed best management practices based on slope position units(基于坡位单元的流域最佳管理措施空间优化)","type":"publication"},{"authors":["高会然","秦承志*","\u003cb\u003e\u003cI\u003e朱良君\u003c/I\u003e\u003c/b\u003e","朱阿兴","刘军志","吴辉"],"categories":null,"content":"","date":1527782400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"5def364a239b5196a7bb8d4983039457","permalink":"http://zhulj.net/zh/publication/2018-dqxxkxxb-bmpsoptslppos/","publishdate":"2018-06-01T00:00:00+08:00","relpermalink":"/zh/publication/2018-dqxxkxxb-bmpsoptslppos/","section":"publication","summary":"基于流域过程模型的BMP情景分析是当前流域管理措施评价、非点源污染控制等研究应用中广泛采用的方法,但其通常采用的BMP空间配置单元(地块、农场、水文响应单元或子流域)与坡面上的地形部位关系较弱,难以有效地根据坡面过程特点表达坡面上多种BMP之间的空间配置关系,影响了BMP情景优化效率和结果的合理性。为此,本文提出以坡位单元作为BMP空间配置单元,将各种BMP在不同坡位间合理的空间配置关系显式表达为基于坡位的空间配置规则,通过结合NSGA-II优化算法建立了一套基于坡位单元的BMP空间配置优化方法。应用案例表明,本文构建的基于坡位单元的BMP情景优化方法可有效利用基于坡位的空间配置规则进行BMP情景优化,优化所得的BMP空间配置方案更为合理,优化效率较高。","tags":["SEIMS","坡位","空间优化","BMPs"],"title":"以坡位为空间配置单元的流域管理措施情景优化方法","type":"publication"},{"authors":["\u003cb\u003e\u003cI\u003e朱良君\u003c/I\u003e\u003c/b\u003e","朱阿兴","秦承志*","刘军志"],"categories":null,"content":"","date":1519833600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"42b74ef3ffb01d7c9fe59fa8653e7bdf","permalink":"http://zhulj.net/zh/publication/2018-geomorp-autofuzslppos/","publishdate":"2018-03-01T00:00:00+08:00","relpermalink":"/zh/publication/2018-geomorp-autofuzslppos/","section":"publication","summary":"坡位（如山脊、背坡、沟谷）的空间渐变特征可为地理建模提供重要的地形信息，这种空间渐变可用空间位置对坡位的模糊隶属度（或称相似度）值定量刻画，称之为模糊坡位。多数基于模糊分类思路的模糊坡位提取方法在数据准备和参数设定时需要大量人为干预，如Qin等（2009）提出的基于原型的模糊推理方法主要包括准备地形属性集、选取坡位典型位置及确定模糊推理参数三个步骤，易用性较差。模糊坡位通常采用的通用地形属性，包括一阶（如坡度）和二阶（如曲率）局部地形属性和区域地形属性（如相对位置指数），可通过自动化算法提取。坡位典型位置可通过地形属性及对应属性范围叠加后得到，属性范围可根据该地形属性的模糊推理函数形状及中心值确定，如S型函数取大于中心值的属性范围。模糊推理函数及参数可结合领域知识和对地形属性频率分布的数据挖掘（如bi-Gaussian模型）得到，如坡度一般由山脊增加至背坡然后减小至沟谷，因此坡度对于背坡的推理函数形状为钟形，结合bi-Gaussian模型拟合结果可最终确定推理参数。基于上述思路，以五类基本坡位为例，实现了一种模糊坡位提取自动化工作流，默认仅需输入研究区格网DEM即可得到提取模糊坡位信息，并允许自定义工作流配置（如参与推理的地形属性等）。自动化工作流涉及的计算密集型算法均基于消息传递并行库实现以提高计算效率。通过两个不同地形特征的研究区应用，表明了所提自动化方法的合理性、易用性和高效性。所提自动化方法思路可为类似地理学空间分析方法的自动化提供借鉴。","tags":["坡位","模糊隶属度","自动化","并行计算"],"title":"Automatic approach to deriving fuzzy slope positions(模糊坡位提取自动化方法)","type":"publication"},{"authors":null,"categories":null,"content":" 0.基本需求  照片、视频集中存放，手机、iPad、Windows、macOS可以访问、播放 iPhone手机照片增量备份 macOS使用TimeMachine备份 出门在外，外网下访问NAS中存放的文件 迅雷远程下载 支持多用户权限  1.硬件配置  HP Gen8一台 Netac/朗科 N3-120GB 固态硬盘 （使用不超过一年就掉盘2次，最后彻底无法识别，不建议购买），用于放在sata5光驱位，装系统 小pin转sata电源线 （怀疑劣质线间歇性断电，不够稳定，目前将固态硬盘置于SATA1口作为系统盘，使用了HP 654540-001 2.5寸转3.5寸硬盘支架），用于固态硬盘连接 西数红盘4T，作为数据盘放在4个硬盘笼中（等以后需要扩容了，直接插上数据盘就能继续工作啦，家用没必要组RAID，因为RAID没办法硬盘休眠）  2.软件架构 Gen8有很多实用的玩法，但是我希望在不更新硬件（CPU、内存、网络）的基础上进行家用，因此选用了较为稳妥的Windows Server 2012 R2 + Hyper-V（黑群晖）的方案。\n 黑群晖通过系统自带NFS服务挂载数据盘中的文件夹，和Server 2012 R2实现文件共享，通过群晖App套件（DS Photo，DS Vedio，DS File等）供手机和iPad访问 Server 2012 R2本身也建立文件服务器，以便Windows和Mac直接访问，而不用经过群晖这一层  3.配置步骤 经过几次失败的配置，将我安装过程总结如下：\n 3.1.将固态硬盘固定在光驱位（如果不需要用U盘引导启动，则直接放在SATA1位置即可），将Server 2012 R2镜像（.iso）文件放入U盘； 3.2.插入U盘，硬盘笼里不要放硬盘，通电，通过路由器或Fing手机软件找到iLO的IP地址，通过IE浏览器访问iLO，并打开远程操作台，通过网页端PowerOn服务器； 3.3.机器经过一阵轰鸣之后进入自检界面，出现F9、F10、F11按键提示的时候，按F10进入Intelligent Provisioning，选择U盘里的镜像进行自动系统安装，IP会自动将HP相关驱动一并装好； 3.4.进入系统之后，什么都不做，第一件事就是把该加装的服务都装上，否则后面装上硬盘、虚拟机之后再添加会出现安装失败的现象。这里我需要把Hyper-V、NFS服务、功能里的Windows Server Backup（用于配置完成之后一次性备份整个Windows Server 2012r2到其他硬盘，以便系统盘挂掉之后恢复）勾选，如果需要链路聚合，推荐使用iLO界面登录的情况下，创建Windows自带的NIC组合； 3.5.在做U盘引导启动和插入硬盘之前，先装上黑群晖，具体参照教程1、教程2、教程3； 3.6.敲代码方式制作U盘引导启动，参考这篇教程; 3.7.此时可以装上硬盘和U盘，重启机器； 3.8a.[不推荐]利用hanewin软件挂载文件夹给黑群晖，参考教程，设置群晖开机自动挂载NFS文件夹，参考教程1和教程2； 3.8b.[推荐]使用Windows原生的NFS挂载了黑群晖，见这里。 3.9.配置Server 2012 R2文件简单共享，当然也可以直接利用黑裙的共享文件夹; 3.10.使用Syncthing同步其他设备，在群晖套件中心添加http://packages.synocommunity.com/ 源即可找到并安装Syncthing； 3.11.黑群晖中利用Docker安装xware实现迅雷远程下载； 3.12.利用花生壳实现内网穿透，便于外网访问黑群晖； 。。。  ","date":1487030400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"f3b48065bd20dd9bd81af5196adaf113","permalink":"http://zhulj.net/zh/post/2017-2-14-gen8_nas/","publishdate":"2017-02-14T00:00:00Z","relpermalink":"/zh/post/2017-2-14-gen8_nas/","section":"post","summary":"随着家庭成员电子设备的增多，照片、视频、文件逐渐增多，为了更好地共享，有必要建立一个集中式的数据中心。\n于是我看到了NAS的概念，于是发现了HP Gen8，于是心中无限长草，终于下定决心，剁了手。经过若干次试错，终于能够总结一下。\n","tags":["NAS"],"title":"德淘Gen8打造家庭NAS","type":"post"},{"authors":null,"categories":null,"content":" 1.软件  Zotero  Zotfile Better Bib(La)TeX  坚果云 手机端  Papership (iOS)  插件  Zotero Connector (Chrome 插件) Word processors add-in   2.Zotero配合坚果云进行文献同步  Zotero\n Preference-Advanced-Files and Folders, Base directory填写坚果云同步目录，Data directory location填写Zotero的文件目录（即为Zotero自己的同步目录，免费用户只有300M空间）  Better BibTex\n Citation keys: [auth:lower]_[journal][\u0026gt;0]_[year]|[auth:lower]_[Title:select,1,1]_[year]  Zotfile\n General settings, 上面填写Zotero自己的数据目录，下面填写坚果云同步目录，最后一级均为storage，如C:\\z_reading\\zotero\\papers\\storage和D:\\mysync\\storage Use subfolder defined by: \\%w|%T|%I|%t\\%y Renaming rules: %a_ %y_ %t  Papership\n  Papership配合坚果云的WebDav服务可以很方便的实现和电脑版一样的体验：浏览文件夹、查看Notes、打开PDF、标注（需app内购）。但是使用WebDav服务有一个对我来讲无法忍受的缺点，同步的文献会被压缩成zip文件传至坚果云，且文件名为无序字符，虽然可以通过PaperShip方便查看，但是并不方便日常查询。\n因此，我放弃了这种同步方案，依然采用的是坚果云同步storage文件夹，Zotfile对文献重命名并链接的方案。\n3.优缺点  优点  多个平台之间文献和PDF文件的同步更新 Zotero提供的全文搜索、全文下载等便利功能 可以导出多个Bib(La)TeX格式的引文库，并实时更新  缺点  Papership不能直接打开PDF，只能是结合Papership保留的Zotero文件夹结构及Tags和Note+坚果云上完整的规范命名后的PDF文件 使用Zotfile对文献进行重命名后，Zotero对PDF文件是文件链接的方式，因此，删除文献后，PDF文档并不会删除，需得同时手动删除   4.文献管理经验 4.1.文献搜集整理  文献通过Zotero Connector插件自动添加，可归于多个分类，如研究内容、文章等 添加原文并由Zotfile重命名后存入storage文件夹，由坚果云同步 添加多个Tags方便查找：  文章类型 [原理、方法、应用] 阅读状态 [DONE、TODO、DOING] 借鉴意义 [重要、参考]  添加一条Notes，可通过PaperShip同步编辑，包括但不仅限于以下内容：  文章亮点 研究区简介 方法步骤 共享数据 …  设置相关文献 (Related)  4.2.文档中插入文献  Better BibTeX插件的自动导出功能可以方便地更新文献库，直接用于LaTeX 通过Zotero的Word插件插入文献，不会受其他人修改的影响  5.一些改进 5.1.Python代码整理storage文件夹 为了方便清理Zotero产生的空白文件夹，以便通过坚果云查找文件，我写了一个简单的Python脚本来删除这些文件夹：\nimport os from shutil import rmtree suffix = ['.pdf', '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx', '.tex', '.txt'] deldirs = [] for root, dirs, files in os.walk(r\u0026quot;D:\\mysync\\storage\u0026quot;): for i in files: for suf in suffix: if i.find(suf) \u0026lt; 0: continue else: break else: # Can not find any useful documents. deldirs.append(root) deldirs = list(set(deldirs)) for deldir in deldirs: print \u0026quot;deleting %s...\u0026quot; % deldir rmtree(deldir)   修改第4行storage路径为你自己的路径 保存文件为*.py，双击即可运行（前提是电脑上正确配置过python） 添加计划任务，每天定期执行该脚本  ","date":1483056000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"ec907c2af1add4a2f8527e8e5a79404f","permalink":"http://zhulj.net/zh/post/2016-12-30-cross-platform-bibliography/","publishdate":"2016-12-30T00:00:00Z","relpermalink":"/zh/post/2016-12-30-cross-platform-bibliography/","section":"post","summary":"Zotero、Zotfile及坚果云进行跨平台文献管理、同步。","tags":["Zotero"],"title":"跨平台(PC、Mac、iPhone)文献管理攻略","type":"post"},{"authors":["王琳","\u003cb\u003e\u003cI\u003e朱良君*\u003c/I\u003e\u003c/b\u003e","朱阿兴","刘军志","沈琳"],"categories":null,"content":"","date":1464710400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"5704fe40b81d6b8c794c1834627647b0","permalink":"http://zhulj.net/zh/publication/2016-synydxxb-swathrudelieffects/","publishdate":"2016-06-01T00:00:00+08:00","relpermalink":"/zh/publication/2016-synydxxb-swathrudelieffects/","section":"publication","summary":"流域空间离散化是SWAT等分布式非点源污染模型的基础,不同的空间单元划分方案会对模型模拟结果产生影响。为合理配置SWAT模型非点源污染模拟中的空间单元划分方案,以太湖地区中田舍流域(42km2)为研究区开展研究:根据汇流累积量阈值和土地利用-土壤-坡度分级面积阈值设计25种子流域(SUB)-空间响应单元(HRU)划分方案,其中以真实河网提取阈值、HRU面积阈值为0%-0%-0%作为基准方案进行日尺度模型率定,并利用该套模型率定参数探讨SWAT非点源污染模拟对空间单元划分的响应。结果表明:模型率定期径流、泥沙、总氮和总磷Nash-Sutcliffe效率系数分别为0.575,0.671,0.483和0.758,模型可以较好表达流域过程;不同的空间单元划分通过对土地利用类型的筛选以及流域过程相关参数的改变影响污染物模拟结果,且模拟结果对HRU划分的敏感性高于子流域划分。因此,利用SWAT进行非点源污染模拟时,应在保证径流、泥沙模拟精度的基础上,进行尽可能详尽的HRU划分(如土地利用-土壤-坡度分级面积阈值分别为0%-0%-0%或0-5%-5%),以更好体现流域空间异质性,避免过粗的HRU集总带来模拟结果的失真,而子流域划分则选取能体现真实河网的适中阈值以体现子流域空间异质性即可。","tags":["SWAT"],"title":"SWAT模型非点源污染模拟对空间单元划分的响应","type":"publication"},{"authors":null,"categories":null,"content":"  参考资料：\n 1.Creating Project Pages manually by Github 2.Automatic Documentation Publishing with GitHub and TravisCI 3.Deploying Docs on Github with Travis-CI   1 手工创建Github Pages # 克隆一个纯净仓库 git clone github.com/user/repository.git # 创建gh-pages分支 cd repository git checkout --orphan gh-pages # 这个gh-pages分支不会影响其他分支，因为它是orphan！ # 删除所有库内文件 git rm -rf . # 创建一个html并push到gh-pages分支 echo \u0026quot;My Page\u0026quot; \u0026gt; index.html git add index.html git commit -a -m \u0026quot;First pages commit\u0026quot; git push origin gh-pages  这样，就可以通过http(s)://\u0026lt;username\u0026gt;.github.io/\u0026lt;projectname\u0026gt;访问项目主页了，比如https://lreis2415.github.io/SEIMS/，注意，repository大小写敏感！\n2 在Travis CI中添加库 使用Github账号登录Travis CI，进入“Account”，找到你想创建文档的Github库，启用它。\n这样就让Travis CI知道了，将来这个库每次push的时候，都要根据库根目录下的.travis.yml配置进行自动构建（文档、程序之类的）。\n3 为Travis CI创建SSH key cd repository mkdir doc ssh-keygen -t rsa -C \u0026quot;youremail@example.com\u0026quot; -f doc/travisci_rsa # travisci_rsa和travisci_rsa.pub会生成在当前仓库目录doc/   3.1.将travisci_rsa.pub中的内容添加至Github库的设置中，即Settings -\u0026gt; Deploy Keys，当然，记得要选中“Allow write access”。 3.2.使用Travis CI提供的加密文件的方案，即Travis CI CLI，对travisci_rsa文件进行加密。\n 3.2.1.从Ruby Gem安装travis，Windows下请首先安装Ruby，替换掉官方的sources，参考这篇博客。\n 3.2.2.Windows下操作（P.S.在我电脑上反正是出错！推荐使用linux！）：\n  gem sources --add http://gems.ruby-china.org/ --remove https://rubygems.org/ gem install travis travis login # 然后输入Github的用户名、密码进行验证 # 创建.travis.yml cd \u0026lt;path/to/your/github/repository\u0026gt; echo \u0026quot;before_install:\u0026quot; \u0026gt; .travis.yml # 然后便可以加密文件了 travis encrypt-file doc/travisci_rsa --add # Output: # encrypting travisci_rsa for lreis/SEIMS # storing result as travisci_rsa.enc # storing secure env variables for decryption # Make sure to add super_secret.txt.enc to the git repository. # Make sure not to add super_secret.txt to the git repository. # Commit all changes to your .travis.yml. # 将travisci_rsa.enc上传至Github，而不要讲travisci_rsa上传，可以将travisci_rsa删掉 rm doc/travisci_rsa # 将以下两行添加至.travis.yml - chmod 0600 travisci_rsa - cp doc/travisci_rsa ~/.ssh/id_rsa   3.2.3.CentOS下操作：  # 安装ruby和gem以安装travis sudo yum install ruby rubygems # 但是这样安装之后，设置好中国的ruby源，安装travis依然遇到各种问题，比如SSL，hostname等。 # ERROR: While executing gem ... # (Gem::RemoteFetcher::FetchError) # hostname was not match with the server certificate (https://gems-10023966.file.myqcloud.com/quick/Marshal.4.8/travis-1.8.2.gemspec.rz) # 因此推荐采用如下Linux服务器RVM安装脚本 # https://github.com/huacnlee/init.d/blob/master/install_rvm vim install_rvm # 粘贴脚本内容 chomd 700 install_rvm # 执行脚本 ./install_rvm # 剩下的操作与Windows类似 gem install travis travis login cd \u0026lt;path/to/your/github/repository\u0026gt; echo \u0026quot;before_install:\u0026quot; \u0026gt; .travis.yml travis encrypt-file doc/travisci_rsa --add rm doc/travisci_rsa  3.3.上一步操作中travis encrypt-file doc/travisci_rsa --add之后，打开Travis CI的库设置页面，发现环境变量里多了2个值，分别为encrypted*_iv和encrypted*_key，这是openssl解密travisci_rsa.enc需要的参数，需要在.yml文件中设置。\n  4 配置Travis CI 上一步中，我们已经在库的根目录下创建了.travis.yml文件，接下来要对其进行进一步编辑。\ndist: trusty branches: only: - master before_install: - openssl aes-256-cbc -K $encrypted_9c89c5b645f3_key -iv $encrypted_9c89c5b645f3_iv -in doc/travisci_rsa.enc -out doc/travisci_rsa -d - sudo apt-get install doxygen graphviz - chmod 0600 doc/travisci_rsa - cp doc/travisci_rsa ~/.ssh/id_rsa # push automatically generated doxygen html files to gh-pages branch - chmod 700 doc/publish-doxygen - \u0026quot;./doc/publish-doxygen\u0026quot; notifications: email:false  5 配置Doxygen 上一步中，构建Doxygen文档使用了doc/publish-doxygen，具体如何配置的呢？\n主要分为以下几步： + 5.1.设置Github库地址、Doxygen文档地址等 + 5.2.克隆一份现有的gh-pages，并清空，以防更新后有旧版本残留 + 5.3.调用doxygen生成代码文档 + 5.4.将html文件夹push到gh-pages分支\n示例代码如下：\n#!/bin/bash -e # Settings REPO_PATH=git@github.com:lreis2415/SEIMS.git HTML_PATH=doc/html COMMIT_USER=\u0026quot;YOUR USERNAME\u0026quot; COMMIT_EMAIL=\u0026quot;YOUR EMAIL\u0026quot; CHANGESET=$(git rev-parse --verify HEAD) # Get a clean version of the HTML documentation repo. rm -rf ${HTML_PATH} mkdir -p ${HTML_PATH} git clone -b gh-pages \u0026quot;${REPO_PATH}\u0026quot; --single-branch ${HTML_PATH} # rm all the files through git to prevent stale files. cd ${HTML_PATH} git rm -rf . cd - # Generate the HTML documentation. #make doxygen doxygen ./doc/Doxyfile echo \u0026quot;Doxygen generated done!\u0026quot; # Create and commit the documentation repo. cd ${HTML_PATH} git add . git config user.name \u0026quot;${COMMIT_USER}\u0026quot; git config user.email \u0026quot;${COMMIT_EMAIL}\u0026quot; git commit -m \u0026quot;Automated doc for changeset ${CHANGESET}.\u0026quot; git push origin gh-pages cd -  6 测试 push到master分支，等待一会，打开项目主页看看效果吧，如https://lreis2415.github.io/SEIMS/。\n当然，如果对Doxygen默认的样式不满意，你还有很多种途径进行定制，这里就不介绍啦。\n","date":1460419200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"8a3976341305b12f2f7eacf375bfddc0","permalink":"http://zhulj.net/zh/post/2016-04-12-automatic-documentation-publishing-with-github-and-travisci/","publishdate":"2016-04-12T00:00:00Z","relpermalink":"/zh/post/2016-04-12-automatic-documentation-publishing-with-github-and-travisci/","section":"post","summary":"利用持续构建工具（Travis CI）及Doxygen自动构建并更新在线文档。","tags":["doxygen","CI","Github"],"title":"如何利用Github Pages, Doxygen和Travis CI构建自动更新文档系统","type":"post"},{"authors":null,"categories":null,"content":" 1 写在前面 由于ArcGIS的广泛使用，ArcSWAT顺理成章成为SWAT建模者的首选，但相信很多人和我一样，使用ArcSWAT（尤其指适配ArcGIS 10.x版本的）时，经常遇到莫名其妙的COM组件错误（如图1），无从查错，只能一遍遍重来……重来……重来……\n图1. ArcSWAT常见错误提示，无从下手\n随着开源GIS软件的蓬勃发展，GRASS、QGIS等优秀软件日臻完善，基于这些软件的第三方插件亦愈加丰富。QSWAT就是这样一款足以替代ArcGIS进行SWAT参数准备及模型构建的用户界面插件。\n本文将从数据准备到软件操作，再到模型运行介绍利用QSWAT进行SWAT建模的过程，希望能够起到SWAT零基础入门的效果。\nP.S.1 写这篇博客时，我也是第一次真正构建、运行、率定SWAT模型，遇到了很多问题，感谢Google SWAT/SWAT-CUP Group以及其他网上博客的帮助。\nP.S.2 官方使用手册永远是最好的资料，在进行QSWAT学习过程中，详细翻阅了多个手册，包括：ArcSWAT2012 User Guide1, SWAT 2012 Input/Output Documentation2, SWAT Theory 20093, SWAT Editor 20124, QSWAT manual5, SWAT-CUP manual6等。\n2 QSWAT安装 按照QSWAT官网的安装教程，按照如下顺序依次安装即可：\n目前QSWAT仅支持32位版本的QGIS-2.6.1，请不要安装最新版QGIS。\n1. QGIS-OSGeo4W-2.6.1-1-Setup-x86.exe 2. SwatEditorInstall.msi 3. QSWATinstall1.3.exe  完成之后，打开QGIS，依次，即可在菜单栏看到QSWAT图标。\n Plugins -\u0026gt; Manage and Install Plugins -\u0026gt; Installed -\u0026gt; QSWAT\n 2.1 MPI配置 QSWAT中利用TauDEM进行地形参数提取（填洼、流向、汇流、河网提取、流域划分等），TauDEM的运行需要MPI并行环境。\n推荐安装微软的MPI实现： Microsoft HPC 2012 MS-MPI，默认安装路径为C:\\Program Files\\Microsoft HPC Pack 2012。\n QSWAT -\u0026gt; QSWAT Parameters\n 进行MPI路径设置，如图2。\n图2. QSWAT中MPI路径设置\n此时，如果运行QSWAT调用TauDEM，会出现下列错误提示：\n------------------- TauDEM command: ------------------- C:/Program Files/Microsoft HPC Pack 2012/Bin\\mpiexec.exe -n 8 C:\\SWAT\\SWATEditor\\TauDEM5Bin\\PitRemove -z G:\\data_m\\qswatTutorial\\zts\\Source\\dem_zts_burned.tif -fel G:\\data_m\\qswatTutorial\\zts\\Source\\dem_ztsfel.tif Fatal protocol error: check version between Mpiexec.exe, Msmpi.dll, and Smpd.exe. *** Problem with TauDEM PitRemove: please examine output above. ***   问题原因： QSWAT调用的是SWATEditor 2012安装时自动安装的TauDEM，而TauDEM的运行需要MPI并行环境支持，由于我们安装的版本是MS HPC Pack 2012，与SWATEditor自带的msmpi.dll不匹配，导致出错。\n 解决办法：将C:\\SWAT\\SWATEditor\\TauDEM5Bin\\msmpi.dll删掉即可！\n  3 数据预处理 SWAT建模最重要的也是最基础的便是数据预处理，作为一个综合的、长时段连续模拟、具有一定物理机理的半分布式流域过程模型，SWAT可以进行水文、侵蚀、污染物、植被生长等模拟，相应地，需要准备相关地形、土地利用、土壤理化属性、农田管理措施（如耕作模式）等数据，在此基础上，按照SWAT模型的要求进行格式整理，这便是SWAT建模数据预处理。\n3.1 空间数据准备 3.1.1 DEM 数字高程模型（DEM）自然不必多说，万里长征第一步，就是准备好比流域范围稍大的适当分辨率DEM。\n3.1.2 土地利用 土地利用图，来源多种多样，可以遥感目视解译，也可地形图数字化，但是重要的一步是按照SWAT内置数据库对土地利用进行重新编码。SWAT内置数据库（QSWATRef2012.mdb，可在安装目录找到，也可在新建工程目录下找到）中有3张表可作为Landuse编码参考，分别是CDL_lu、nlcd_lu、nlcd2001_lu。需要准备：\n 1.栅格或矢量土地利用图（编码可随意，也可按照上述3张表中编码）\n 2.土地利用查找表(.csv)，内容类似：\n  Value,Landuse 1,AGRL 18,WATR 104,URLD 6,FRST  3.1.3 土壤 与土地利用数据准备类似，土壤数据也需进行重编码和准备查找表。值得一提的是，SWAT内置了美国土壤数据库，并不符合中国土壤情况，因此，我们需要自建土壤数据库。\n 1.从QSWATRef2012中将usersol表导出为usersol.xlsx；\n 2.编辑usersol.xlsx：将研究区土壤类型（如Heishatu、Xiaofenshatu等）追加至表中；\n 3.补充土壤类型对应的理化性质，参数可查地方土壤志，也可采样获得，不再赘述；\n 4.将编辑好的usersol.xlsx导入QSWATRef2012.mdb中，并覆盖原表(如下图)，否则在4.2 HRU划分中会出现找不到土壤类型定义的错误（如图3）。\n  具体操作步骤为，一定注意，不要主键！\n Access -\u0026gt; 外部数据 -\u0026gt; Excel -\u0026gt; 将数据导入当前数据库的新表中 -\u0026gt; 连着3个下一步 -\u0026gt; 不要主键 -\u0026gt; usersol -\u0026gt; 确定\n 图3. 土壤类型未定义错误提示\n 5.土壤数据查找表(.csv)，内容类似：  Value,Name 1,Heishatu 2,Xiaofenshatu 3,Huangshatu  3.1.5 坑塘 (Optional) 坑塘或水库模拟可根据研究区实际情况取舍。坑塘数据的准备最好是在子流域划分之后进行，因为坑塘在SWAT是集总式表达，并没有空间位置，而是每个子流域一套参数。放在这里因为同属通过数据预处理获得模型参数。\n要获取的坑塘物理参数主要有PND_FR、PND_PSA、PND_PVOL、PND_ESA、PND_EVOL、PND_VOL，通过GIS分析我们可以得到PND_FR，进而其余面积、容积参数可求。\n下面主要介绍如何计算PND_FR。\n所用python脚本托管在Github上。\n PND_FR: Fraction of subbasin area that drains into ponds.\n 读者可以在4.1 模型参数编辑之后回到这里进行坑塘数据提取！\n 1.从土地利用中提取坑塘，并转换为与DEM分辨率、空间范围（Extent）均一致的栅格，如图4(a)；\n 2.为避免影响后续upstream area的计算，从pond中剔除stream栅格，如图4(b)；\n 3.调用TauDEM工具DinfUpDependence计算pond的upstream area，得到的栅格值域为[0,1]；\n 4.设置阈值（如0.9），大于该阈值的栅格认为是能够汇入坑塘的；\n 5.利用子流域范围划分上述栅格并计算面积，与子流域面积之比，即为PND_FR，如图4\u0026copy;。\n  图4. 坑塘物理数据预处理\n3.2 气象数据准备 降水是地表水过程的主要水来源，对模型构建起到至关重要的作用。\n气象数据的准备包括逐日降水、逐日最高/最低气温，当然如果资料丰富，也可准备逐日相对湿度、太阳辐射等数据；以及气象站点逐月数据（温度、相对湿度、太阳辐射等等）。\n具体数据格式，在相关参考文献中都有详解，这里不再赘述。\n我准备的数据包括：\npcpfork.txt 降水站点信息（站名、经纬度、高程等） pcp_LYQ.txt 降水站降水数据（该文件名应在pcpfork.txt中有定义） tempfork.txt\t温度站点信息 temp_LYQ.txt\t温度站温度数据 WGEN_LYQ.xlsx\t气象站逐月数据（Excel中应包含WGEN_user数据表）  3.3 管理措施准备 管理措施数据直接影响对非点源污染的模拟。\n因此，需要结合研究区实际情况，进行管理措施数据的整理：\n 1.从QSWATRef2012.mdb中将OpSchedules表导出为OpSchedules.xlsx;\n 2.编辑OpSchedules.xlsx：新增一种管理模式，如南方水旱轮作AGRL_zts,可以按照绝对日期设置耕地、施肥、播种、灌溉、收获，但是一般推荐使用积温进行设置，即Heat unit scheduling, 值得注意的是：\n   当HRU没有任何作物生长时，积温比例为全年的，而当播种操作完整之后，一直到作物收获，积温比例为该作物生长期内的积温与作物生长所需总积温之比！\n 3.编辑完成之后，导入QSWATRef2012.mdb，并覆盖原表，待用。  3.4 观测资料整理（径流、泥沙、污染物等） 观测资料的整理需要做的就是与降水逐日对比，发现并剔除异常值：因为，降水和径流、泥沙的趋势是大致一致的。\n4 利用QSWAT建模 准备好所有数据之后，便可以运行QSWAT建模了。点击新建工程，指定保存路径后，开始向导式建模（图5）。\n图5. 新建QSWAT工程\n4.1 子流域划分 具体步骤如图6所示，不再文字赘述！\n图6. 子流域划分步骤\n4.2 HRUs划分 具体步骤如图7所示，不再文字赘述！\n图7. HRU划分步骤\n4.3 模型参数编辑 通过以上2个步骤，QSWAT为SWAT的运行准备好了基本的空间参数，接下来，对SWAT数据库进行编辑，交给SWATEditor啦（Step 3 Edit Input and Run SWAT）。\n点击Setp3之后，打开SWAT Editor软件界面，首先点击“Connect to Database”建立与Access数据库的连接.\n4.3.1 气象数据导入  Write Input Tables -\u0026gt; Weather Stations\n 按照3.2 气象数据准备情况，依次设置Weather Generator Data、Rainfall Data、Temperature Data，如图8。\n图8. 气象数据导入\n随后:\n Write Input Tables -\u0026gt; Write SWAT Input Tables, Select All -\u0026gt; Create Tables\n 这样便将之前所有的数据预处理操作写入了SWAT数据库，即\u0026lt;project name\u0026gt;.mdb，如zts.mdb。\n4.3.2 坑塘数据(optional) 如果进行了3.1.5 Pond (Optional)步骤，则在这里应该将坑塘数据更新： 两种方式：\n 1.直接使用SWAT Editor逐个子流域进行编辑   Edit SWAT Input -\u0026gt; Subbasin Data -\u0026gt; Pond (.pnd) -\u0026gt; Select subbasin ID -\u0026gt; OK -\u0026gt; Edit Values -\u0026gt; Save Edits -\u0026gt; Exit\n  2.另一种方法与3.1.3 Soil中的操作类似，即从\u0026lt;project name\u0026gt;.mdb中导出pnd表至pnd.xlsx,编辑之后，重新导入数据库并覆盖原表。  4.3.3 管理措施数据 管理措施数据由于需要对不同种类的HRU设置，数据库中生成对应HRU数量的记录，不便于自动操作，因此，采用手工设置的方法。\n 1.打开管理措施设置界面   Edit SWAT Input -\u0026gt; Subbasin Data -\u0026gt; Management (.mgt)\n 图9. 打开管理数据边界界面\n 2.选取某一类HRU，比如这里我选择了所有土地利用为AGRL的HRU，打开设置窗口之后，按照图9所示的步骤依次操作，即可完成该类HRU管理措施的配置。  图10. 设置管理数据\n4.4 设置及运行模型 到此为止，我们已经基本完成了模型构建的工作，下面开始首次运行模型。\n 1.从SWAT数据库中读取并写入所有运行所需文件（即TxtInOut文件夹）   Edit SWAT Input -\u0026gt; Re-Write SWAT Input Files\n 如图11所示，这样，SWAT Editor便将SWAT运行所需的所有文件从\u0026lt;project name\u0026gt;.mdb数据库导出至\u0026lt;project path\u0026gt;\\Scenarios\\Default\\TxtInOut中。\n图11. 写入SWAT运行所需所有文件\n SWAT的运行的全部所需数据全在该文件夹下！\n 2.运行模型   SWAT Simulation -\u0026gt; Run SWAT\n 图12所示为SWAT运行前设置界面，设置模拟起止日期、SWAT版本、输出选项（Daily）等之后，点击Setup SWAT Run -\u0026gt; Run SWAT之后，便可看到图13所示的运行窗口。\n图12. 设置并运行SWAT\n图13. SWAT运行窗口\n4.5 模型结果可视化 模型运行结束之后，需要查看径流、泥沙等模拟与实测值的差异，以便分析原因，进行参数调整。\n 1.将河道结果（.rch）写入输出数据库，便于读取、分析   SWAT Simulation -\u0026gt; Read SWAT Output\n 结果数据库文件为\u0026lt;project path\u0026gt;\\Scenarios\\Default\\TablesOut\\SWATOutput.mdb\n 2.在QSWAT界面打开Setp 4 Visualise，参照图14进行设置，即可得到图15所示的流域出口实测与模拟径流结果。  通过图14的流量过程线，最直观的分析结论为：\n 洪峰流量过大\n 基流过高\n  而此时模型默认的参数下Nash系数为0.15，需要针对产流、地下水、蒸散发等过程参数进行调参，将另行文介绍。\n图14. SWAT输出可视化窗口设置\n图15. 实测与径流模拟结果\n5 常见错误 5.1 Python相关  Python访问受限，解决方案：以管理员方式运行QGIS即可  图16. Python访问受限错误\n6 总结 流域是多过程复杂交互的系统，流域模型是对其进行简化的物理、数学表达，对流域基础空间数据、管理数据等尽可能准确的认识，是得到较好模拟结果的前提和保证。\n本文从中国南方湿润区小流域的实际情况出发，比通常步骤多加了坑塘数据的设置，使得完全默认参数下的径流模拟已趋于合理。\n接下来，通过简单几个手工调参，便可达到较好结果，随后，利用SWAT-CUP进行自动调参，得到更优参数。\n相信很多SWAT建模者和我一样，都希望将SWAT-CUP自动率定结果重新写回SWAT数据库（.mdb），以便在可视化界面SWAT Editor中进一步修改调整，但是SWAT或SWAT-CUP官方并没有提供相应的工具，我用Python初步实现了这个功能，希望感兴趣的进行试用并提出宝贵建议，请移步这里。\nReference  Winchell, M., Srinivasan, R., Diluzio, J., Arnold, J.G., 2013. ArcSWAT Interface for SWAT 2012, User\u0026rsquo;s Guide. ^ Arnold, J.G., Kiniry, J.R., Srinivasan, R., Williams, J.R., Haney, E.B., Neitsch, S.L., 2013. SWAT 2012 Input/Output Documentation. Texas Water Resources Institute. ^ Neitsch, S.L., Arnold, J.G., Kiniry, J.R., Williams, J.R., 2011. Soil and Water Assessment Tool Theoretical Documentation, Version 2009. Texas A\u0026amp;M University System, College Station, Texas, USA. ^ Winchell, M.,Srinivasan, 2012. SWAT Editor for SWAT 2012 Documentation. Texas Water Resources Institute. ^ Dile, Y.H., Srinivasan, R., George C., 2016. QGIS Interface for SWAT (QSWAT). ^ Abbaspour, K.C., 2015. SWAT-CUP: SWAT calibration and uncertainty programs - A User Manual. Eawag. ^   ","date":1460332800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"5c2a4272aadd54fd098de5a3508e642e","permalink":"http://zhulj.net/zh/post/2016-04-10-qswat-manual/","publishdate":"2016-04-11T00:00:00Z","relpermalink":"/zh/post/2016-04-10-qswat-manual/","section":"post","summary":"由于ArcGIS的广泛使用，[ArcSWAT](http://swat.tamu.edu/software/arcswat/ \"ArcSWAT\")顺理成章成为SWAT建模者的首选，但相信很多人和我一样，使用ArcSWAT（尤其指适配ArcGIS 10.x版本的）时，经常遇到莫名其妙的COM组件错误，无从查错，只能一遍遍重来……重来……重来…… 为何不试试开源的[QSWAT](http://swat.tamu.edu/software/qswat/ \"QSWAT\")呢？\n","tags":["QSWAT"],"title":"利用QSWAT进行SWAT建模(QSWAT教程)","type":"post"},{"authors":null,"categories":null,"content":" 0 更新说明 0.1.关于时制和日界的问题（2017-7-25） 该数据集采用的是“北京时，日界20时”，也就是说记录为“2013-02-04”的数据应为“2013-02-04 20:00:00”，是“2013-02-03 20:00:01 ~ 2013-02-04 20:00:00 UTC+8” （当然，认为是“2013-02-03 20:00:00 ~ 2013-02-04 19:59:59 UTC+8”也可）这段时间的属性值，转换为UTC时间为“2013-02-04 12:00:00”。\n原始数据格式为“YYYY MM DD”，为了方便使用，数据库中统一将时间保存为“YYYY MM DD 20:00:00”，即“北京时 UTC+8”！\n0.2.关于数据更新频率 可根据官网的数据更新频率实时更新，一般来讲延迟半年，即2018年6月可获取最新至2017年12月31日的数据。\n1 需求分析  “中国地面气候资料日值数据集(V3.0)”包含了中国824个基准、基本气象站1951年1月以来本站气压、气温、降水量、蒸发量、相对湿度、风向风速、日照时数和0cm地温要素的日值数据。截至2017年12月31日的数据量为8.35 GB。\n 降水、气温、风速、相对湿度等气象资料对流域建模是至关重要的数据，中国气象数据网为我们提供了良好的数据共享平台。其中，最常用的当属中国地面气候资料日值数据集(V3.0)，其站点分布如图1所示（实际下载下来是839个），目前数据已更新至2017年12月。\n图1. 中国839个基准、基本气象站分布图\n但是，网站更新之后，数据只能按照时间检索，如图2所示，对只想下载某几个站点非常不便。\n图2. 中国地面气候资料日值数据集(V3.0)数据检索界面\n但是，这样下载下来是存有每月数据的链接，如图3所示。\n图3. 下载链接\n手动逐条下载显然不太现实，即便是逐条下载了，每个数据文件含有800多个站点某个月的某一类指标（降水、气温等）的数据，因此，如果想得到某个站点某时间段内所有气象指标数据，实属不易。\n因此，考虑：\n 1.批量下载数据文件（txt）；\n 2.读取数据并按站点存入数据库（SQLite）；\n 3.按照站点及时间范围从数据库中提取数据。\n  2 实现 2.1 批量下载 批量下载比较简单，调用urllib2库即可，核心代码如下：\ndef downloadByUrl(curUrl, filePath): f = urllib2.urlopen(curUrl) data = f.read() with open(filePath, \u0026quot;wb\u0026quot;) as code: code.write(data)  2.2 存入数据库 包括气象站点数据结构及如何写入SQLite数据库代码设计。\n2.2.1 气象站点数据结构  原始记录中，每条记录均包含站点编号、经纬度、高程，造成数据冗余，因此设计一个站点父类climateStation，保存这些信息：  class climateStation: ''' base class of climate station :method: init(ID, lat, lon, alti) :method: printSation() ''' def __init__(self, ID = '', lat=9999, lon=9999, alti=9999): self.count = 0 self.StationID = ID ## 5 digits self.lat = lat ## latitude, float degree self.lon = lon ## longitude, float degree self.alti = alti ## altitude, as ORIGIN: unit 0.1 meter def printStation(self): print('%s, %.3f, %.3f, %.1f' % (self.StationID, self.lat, self.lon, self.alti)   随后设计子类climateFeatures，用于保存每个站点所有的气象数据，其中initValues()方法用于添加一天记录时进行赋初值，assignValuesByFtCode(idx, ftCode, ClimValues)方法根据索引idx、气象数据类型ftCode和数据值ClimValues对当天数据进行修改，check()方法用于检查该站点数据是否具有一致条数，printFeature()方法用于打印该站点信息：  class climateFeatures(climateStation): ''' sub-class of climate feature :method: init(ID, lat, lon, alti) :method: initValues() :method: assignValuesByFtCode(idx, ftCode, ClimValues) :method: check() :method: printFeature() ''' def __init__(self, ID = '', lat=9999, lon=9999, alti=9999): climateStation.__init__(self, ID, lat, lon, alti) self.count = 0 self.date = [] ## date self.avgPRS = [] ## average pressure of the day, ORIGIN: unit 0.1 hPa self.maxPRS = [] ## maximum pressure of the day, ORIGIN: unit 0.1 hPa self.minPRS = [] ## minimum pressure of the day, ORIGIN: unit 0.1 hPa self.avgTEM = [] ## average temperature of the day, ORIGIN: unit 0.1 degree self.maxTEM = [] ## maximum temperature of the day self.minTEM = [] ## minimum temperature of the day self.avgRHU = [] ## average relative humidity, unit 1% self.minRHU = [] ## minimum relative humidity, nuit 1% self.PRE208 = [] ## precipitation from 20:00 to 8:00 self.PRE820 = [] ## precipitation from 8:00 to 20:00 self.PRE = [] ## precipitation from 20:00 to 20:00, ORIGIN: unit 0.1 mm self.smEVP = [] ## small evaporation, ORIGIN: unit 0.1 mm self.lgEVP = [] ## large evaporation, ORIGIN: unit 0.1 mm self.avgWIN = [] ## mean wind speed, ORIGIN: unit 0.1 m/s self.maxWIN = [] ## maximum wind speed, ORIGIN: unit 0.1 m/s self.maxWINASP = [] ## aspect of maximum wind speed self.extWIN = [] ## extreme wind speed self.extWINASP = [] ## aspect of extreme wind speed self.SSD = [] ## sunshine duration hours, ORIGIN: 0.1 hour self.avgGST = [] ## average ground surface temperature of the day, ORIGIN: 0.1 degree self.maxGST = [] ## maximum ground surface temperature of the day, ORIGIN: 0.1 degree self.minGST = [] ## minimum ground surface temperature of the day, ORIGIN: 0.1 degree def initValues(self): self.count += 1 self.avgPRS.append(9999) self.maxPRS.append(9999) self.minPRS.append(9999) self.avgTEM.append(9999) self.maxTEM.append(9999) self.minTEM.append(9999) self.avgRHU.append(9999) self.minRHU.append(9999) self.PRE208.append(9999) self.PRE820.append(9999) self.PRE.append(9999) self.smEVP.append(9999) self.lgEVP.append(9999) self.avgWIN.append(9999) self.maxWIN.append(9999) self.maxWINASP.append(9999) self.extWIN.append(9999) self.extWINASP.append(9999) self.SSD.append(9999) self.avgGST.append(9999) self.maxGST.append(9999) self.minGST.append(9999) def assignValuesByFtCode(self, idx, ftCode, ClimValues): ## ['PRS', 'TEM', 'RHU', 'PRE', 'EVP', 'WIN', 'SSD', 'GST'] if ftCode == 'PRS' and len(ClimValues) == 3: self.avgPRS[idx] = ClimValues[0] self.maxPRS[idx] = ClimValues[1] self.minPRS[idx] = ClimValues[2] elif ftCode == 'TEM' and len(ClimValues) == 3: self.avgTEM[idx] = ClimValues[0] self.maxTEM[idx] = ClimValues[1] self.minTEM[idx] = ClimValues[2] elif ftCode == 'RHU' and len(ClimValues) == 2: self.avgRHU[idx] = ClimValues[0] self.minRHU[idx] = ClimValues[1] elif ftCode == 'PRE' and len(ClimValues) == 3: self.PRE208[idx] = ClimValues[0] self.PRE820[idx] = ClimValues[1] self.PRE[idx] = ClimValues[2] elif ftCode == 'EVP' and len(ClimValues) == 2: self.smEVP[idx] = ClimValues[0] self.lgEVP[idx] = ClimValues[1] elif ftCode == 'WIN' and len(ClimValues) == 5: self.avgWIN[idx] = ClimValues[0] self.maxWIN[idx] = ClimValues[1] self.maxWINASP[idx] = ClimValues[2] self.extWIN[idx] = ClimValues[3] self.extWINASP[idx] = ClimValues[4] elif ftCode == 'SSD' and len(ClimValues) == 1: self.SSD[idx] = ClimValues[0] elif ftCode == 'GST' and len(ClimValues) == 3: self.avgGST[idx] = ClimValues[0] self.maxGST[idx] = ClimValues[1] self.minGST[idx] = ClimValues[2] else: exit(1) def check(self): if self.count == len(self.date) \\ == len(self.avgPRS) == len(self.maxPRS) == len(self.minPRS) \\ == len(self.maxTEM) == len(self.minTEM) == len(self.avgTEM) \\ == len(self.avgRHU) == len(self.minRHU) \\ == len(self.PRE208) == len(self.PRE820) == len(self.PRE) \\ == len(self.smEVP) == len(self.lgEVP) \\ == len(self.avgWIN) == len(self.maxWIN) == len(self.maxWINASP) \\ == len(self.extWIN) == len(self.extWINASP) == len(self.SSD) \\ == len(self.avgGST) == len(self.maxGST) == len(self.minGST): return True else: return False def printFeature(self): print('%s, lat=%.3f, lon=%.3f, alti=%.1f, count=%d, date=%s, PRS=%s, TEM=%s,' ' RHU=%s, PRE=%s, EVP=%s, WIN=%s, SSD=%s, GST=%s' % (self.StationID, self.lat, self.lon, self.alti, self.count, self.date, self.avgPRS, self.avgTEM, self.avgRHU, self.PRE, self.lgEVP, self.avgWIN, self.SSD, self.avgGST))  2.2.2 写入SQLite数据库 逐个数据文件读取完之后，得到存有所有站点所有数据的数据字典，即：\nall_station_climate_data = {} ## format: StationID: climateFeatures()  设计函数writeClimateDataToDatabase(allClimData, dbpath)将数据写入数据库：\ndef writeClimateDataToDatabase(allClimData, dbpath): ''' write climate data to database :param allClimData: climate data of all stations' directionary :param dbpath: path of Sqlite database ''' print \u0026quot;Write climate data to database...\u0026quot; conn = sqlite3.connect(dbpath) count = 1 for station in allClimData: print \u0026quot;---%d / %d, station ID: %s...\u0026quot; % (count, len(allClimData), allClimData[station].StationID) count += 1 stationTabName = 'S' + allClimData[station].StationID create_climdata_tab_sql = '''CREATE TABLE IF NOT EXISTS %s ( stID varchar(5) NOT NULL, date datetime DEFAULT NULL, avgPRS int DEFAULT 9999, maxPRS int DEFAULT 9999, minPRS int DEFAULT 9999, avgTEM int DEFAULT 9999, maxTEM int DEFAULT 9999, minTEM int DEFAULT 9999, avgRHU int DEFAULT 9999, minRHU int DEFAULT 9999, PRE208 int DEFAULT 9999, PRE820 int DEFAULT 9999, PRE int DEFAULT 9999, smEVP int DEFAULT 9999, lgEVP int DEFAULT 9999, avgWIN int DEFAULT 9999, maxWIN int DEFAULT 9999, maxWINASP int DEFAULT 9999, extWIN int DEFAULT 9999, extWINASP int DEFAULT 9999, SSD int DEFAULT 9999, avgGST int DEFAULT 9999, maxGST int DEFAULT 9999, minGST int DEFAULT 9999 )''' % stationTabName #print create_climdata_tab_sql ### create current station climate data table createTable(create_climdata_tab_sql, conn) ### insert station information curClimateData = allClimData[station] fetchone_sql = 'SELECT * FROM %s WHERE stID = ? AND date = ?' % stationTabName update_sql = '''UPDATE %s SET avgPRS = ?, maxPRS = ?, minPRS = ?, \\ avgTEM = ?, maxTEM = ?, minTEM = ?, avgRHU = ?, minRHU = ?,\\ PRE208 = ?, PRE820 = ?, PRE = ?, \\ smEVP = ?, lgEVP = ?, avgWIN = ?, maxWIN = ?,\\ maxWINASP = ?, extWIN = ?, extWINASP = ?, SSD = ?,\\ avgGST = ?, maxGST = ?, minGST = ? WHERE stID = ? AND date = ?''' \\ % stationTabName save_sql = '''INSERT INTO %s values (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)''' % stationTabName for i in range(curClimateData.count): # If the current station record exists, then update it, else insert one. uniqueitem = [curClimateData.StationID, curClimateData.date[i]] dataRow = [curClimateData.StationID, curClimateData.date[i], curClimateData.avgPRS[i], curClimateData.maxPRS[i], curClimateData.minPRS[i], curClimateData.avgTEM[i], curClimateData.maxTEM[i], curClimateData.minTEM[i], curClimateData.avgRHU[i], curClimateData.minRHU[i], curClimateData.PRE208[i], curClimateData.PRE820[i], curClimateData.PRE[i], curClimateData.smEVP[i], curClimateData.lgEVP[i], curClimateData.avgWIN[i], curClimateData.maxWIN[i], curClimateData.maxWINASP[i], curClimateData.extWIN[i], curClimateData.extWINASP[i], curClimateData.SSD[i], curClimateData.avgGST[i], curClimateData.maxGST[i], curClimateData.minGST[i]] # print(dataRow) if fetchOneRecord(conn, fetchone_sql, uniqueitem): updateRecord(conn, update_sql, dataRow[2:] + uniqueitem) continue saveRecord(conn, save_sql, dataRow) conn.commit() conn.close()  2.3 读取数据库 读取数据库设计，包括查询条件输入格式及查询函数设计。\n2.3.1 输入查询条件 查询条件包括站号（为空则查询所有站点），起始时间和终止时间：\n## Input parameters SQLITE_DB_PATH = r'...\\SURF_CLI_CHN_MUL_DAY_V3.0.db' QUERY_STATION_IDs = [] ## leave it blank to query all stations QUERY_DATE_FROM = [1951,1,1] ## format: Year, Month, Day QUERY_DATE_END = [2015,12,31] SAVE_PATH = r'...\\results'  2.3.2 查询函数设计 输出为：\n 1.站点经纬度、高程信息文件：stationInfo.csv\n 2.按站点名命名的气象数据文件：e.g., S50527.csv\n  def QueryDatabase(dbpath, savePath, stationIDs, startTime, endTime): ''' Query and save data from Sqlite database :param dbpath: :param savePath: :param stationIDs: :param startTime: :param endTime: :return: ''' tableList = getTablesList(dbpath) conn = sqlite3.connect(dbpath) stationInfoCSVPath = savePath + os.sep + 'stationInfo.csv' stationInfoData = [] if stationIDs == []: stationIDs = getTablesList(dbpath) else: for i in range(len(stationIDs)): stationIDs[i] = 'S' + stationIDs[i] for tabName in stationIDs: #tabName = 'S' + stationID stationID = tabName[1:] if tabName in tableList: csvPath = savePath + os.sep + tabName + '.csv' startT = datetime.datetime(startTime[0], startTime[1], startTime[2]) endT = datetime.datetime(endTime[0], endTime[1], endTime[2]) startTStr = startT.strftime(\u0026quot;%Y-%m-%d %H:%M:%S\u0026quot;)[:10] endTStr = endT.strftime(\u0026quot;%Y-%m-%d %H:%M:%S\u0026quot;)[:10] fetch_data_sql = '''SELECT * FROM %s WHERE date BETWEEN \u0026quot;%s\u0026quot; AND \u0026quot;%s\u0026quot; ORDER BY date''' % (tabName, startTStr, endTStr) #print fetch_data_sql data = fetchData(conn,fetch_data_sql) saveToCSV(data, csvPath) fetch_station_sql = '''SELECT * FROM stationInfo WHERE stID=%s ''' % (stationID) stationInfoData.append(fetchData(conn,fetch_station_sql)) saveToCSV(stationInfoData, stationInfoCSVPath,'stationInfo') conn.close()  3 站点经纬度及高程信息  当完成数据库构建之后，我查询了几个站点，发现经纬度和高程信息与之前看到的有细微差异！\n检查后发现，我的代码是以站点编号进行索引的，而默认了其经纬度、高程信息是正确且无误的。\n显然，事实并非如此，我又重新跑了一遍数据，找到并总结了每个站点的不同信息（经纬度和高程），比如下图这样，不知道气象共享网的数据库是怎么设计的，难道没有检查过站点的经纬度和高程信息吗？\nExcel表格可以点击这里下载。\n4 总结  就是为了简单实现这么个功能，代码没进行优化设计，8G多的数据读取并存入一个数据字典中，非常耗时。\n 最终得到的SQLite数据库文件大小为1.61 GB，SQLite打开如图4。\n  图4. SURF_CLI_CHN_MUL_DAY_V3.0数据库截图\n5 数据获取 自从本博客发表以来，已经累计帮助了几十位同学、老师、同行。如果对该数据集有兴趣，可邮件联系。\n另外，欢迎技术交流。\nGithub: 创建数据库、查询数据库\nEmail: crazyzlj@gmail.com\n","date":1460332800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"ea24305519e985844ebe9288c73b6a1a","permalink":"http://zhulj.net/zh/post/2016-04-11-constructing-surf_cli_chn_mul_day_v3.0-database/","publishdate":"2016-04-11T00:00:00Z","relpermalink":"/zh/post/2016-04-11-constructing-surf_cli_chn_mul_day_v3.0-database/","section":"post","summary":"利用Python批量下载中国地面气候资料日值数据集(V3.0)数据集，并将原始数据整理为易用格式存入SQLite数据库，随后可根据站点号和起止日期查询数据。\n","tags":["Python","Dataset"],"title":"批量下载中国地面气候资料日值数据集(V3.0)并建立SQLite数据库","type":"post"},{"authors":["\u003cb\u003e\u003cI\u003e朱良君\u003c/I\u003e\u003c/b\u003e","张光辉*","李振炜","耿韧"],"categories":null,"content":"","date":1448899200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"b888c7bcf9ebccfec7a7accbdb23989b","permalink":"http://zhulj.net/zh/publication/2015-sdxb-laserscanner/","publishdate":"2015-12-01T00:00:00+08:00","relpermalink":"/zh/publication/2015-sdxb-laserscanner/","section":"publication","summary":"细沟侵蚀形态的准确测量对解释坡面侵蚀产沙机理、促进侵蚀预报模型发展具有重要意义。基于线结构光技术在实验室可移动水槽上设计了方便组装拆卸、扫描配置灵活、亚毫米级精度的细沟侵蚀形态快速测量系统,摄像机-激光器夹角、扫描速度灵活可调。本研究中,有效测量范围为4.6 m×1.0 m,当摄像机-激光器夹角为25°、扫描速度为10 mm/s时,横断面方向、扫描方向、垂直方向实测分辨率平均分别为0.44 mm、0.50 mm、0.51mm,横断面、垂直方向测量值绝对误差平均值分别为0.22 mm、0.16 mm,测量性能优于前人研究结果。同时,坡面细沟测量实例表明本系统测量结果准确、可靠,在土壤侵蚀相关领域中具有较高的实用价值。","tags":["Experiments"],"title":"一种基于线结构光技术的细沟形态测量系统","type":"publication"},{"authors":["胡国芳","张光辉*","\u003cb\u003e\u003cI\u003e朱良君\u003c/I\u003e\u003c/b\u003e"],"categories":null,"content":"","date":1433088000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"58abd4f58174dd15ff0baad717768f7a","permalink":"http://zhulj.net/zh/publication/2015-stbctb-olflowmeasurementcmp/","publishdate":"2015-06-01T00:00:00+08:00","relpermalink":"/zh/publication/2015-stbctb-olflowmeasurementcmp/","section":"publication","summary":"[目的]为坡面流水深的快速、准确测量提供技术支撑。[方法]采用超声波系统测量变坡试验水槽不同坡度和流量条件下坡面流水深,同时用测针法和染色法对其进行平行测量,利用平均绝对误差(MAE),平均相对误差(MRE),相对均方差误差(RRMSE)和Nash—Sultcliffe系数(NSE)4个指标比较超声波法和染色法或测针法测量数据的接近程度。[结果]通过对3种方法测量结果的比较分析发现,不管以测针法还是以染色法的测量值为参照,超声波法测量的水深值与参照值更接近且相关程度更高。[结论]超声波法能快速有效地测量坡面流水深,用于侵蚀静床坡面流水动力学、土壤侵蚀机理等相关的研究工作。","tags":["Experiments"],"title":"3种坡面流水深测量方法比较","type":"publication"},{"authors":["\u003cb\u003e\u003cI\u003e朱良君\u003c/I\u003e\u003c/b\u003e","张光辉*"],"categories":null,"content":"","date":1380556800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"7151bb7ede7a1388250be579a306e9ea","permalink":"http://zhulj.net/zh/publication/2013-zgstbckx-reviewquantificationmicrotopography/","publishdate":"2013-10-01T00:00:00+08:00","relpermalink":"/zh/publication/2013-zgstbckx-reviewquantificationmicrotopography/","section":"publication","summary":"地表微地形测量是地表粗糙度定量化的基础,对地表形态动态监测、水文过程模拟以及土壤侵蚀过程模型的构建具有重要意义。目前,微地形测量方法主要分为接触式和非接触式2大类,前者包括测针法、链条法、差分GPS法等,后者包括超声波测距法、红外线传感器法、结构光激光扫描法、激光测距扫描法、三维激光扫描仪法、近景摄影测量法等。在全面回顾各方法原理、优缺点及其应用的基础上,分析地表粗糙度定量化常用方法:统计方法指数、地统计学指数和分形及多重分形模型。认为:1)差分GPS法、结构光激光扫描法、三维激光扫描仪法和近景摄影测量法将在亚毫米~厘米级地表微地形测量及地表粗糙度多尺度特征研究中发挥重要作用,同时简单、方便的测针法可能在野外测量中依然占据主导地位;2)以地表微地形测量技术为基础,在土壤侵蚀过程模型中亟需形成一套完整的'测量—定量化—模型应用'范式,同时应加强对地表微地形空间异质性和各向异性的研究,发展新的统一的地表粗糙度定量化方法。","tags":["Experiments"],"title":"地表微地形测量及定量化方法研究综述","type":"publication"},{"authors":["\u003cb\u003e\u003cI\u003e朱良君\u003c/I\u003e\u003c/b\u003e","张光辉*","胡国芳","王兵"],"categories":null,"content":"","date":1359648000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"b6591d73848703685abf47f6d4b480ea","permalink":"http://zhulj.net/zh/publication/2013-stbcxb-olflowultrasonicmeasurement/","publishdate":"2013-02-01T00:00:00+08:00","relpermalink":"/zh/publication/2013-stbcxb-olflowultrasonicmeasurement/","section":"publication","summary":"坡面流水深是常用的水动力学参数,是计算坡面流流速、水流剪切力、水流功率的基础,因而对其准确测量至关重要。室内侵蚀静床实验中水深直接测量法耗时长、误差大,而间接测量法一般是通过染色法测定流速进而反推出坡面流水深,测量精度受水流流态、测流区长度和含沙量等因素影响。鉴此,对超声波距离传感器应用于侵蚀静床坡面流水深测量进行系统研究,通过参数调试和测量系统检验,表明超声波水深测量系统测量不同厚度玻璃的平均相对误差为1.73%,对不同坡度、不同流量组合下坡面流测距的变异系数在0.061%～0.096%之间,其精度能够满足室内侵蚀静床条件下坡面流水深测量的研究需求,可用于侵蚀静床条件下坡面流水动力学特性、坡面流挟沙力、输沙及模拟覆盖对坡面流水动力学特性潜在影响的研究。","tags":["Experiments"],"title":"坡面流超声波水深测量系统研究","type":"publication"},{"authors":["\u003cb\u003e\u003cI\u003e朱良君\u003c/I\u003e\u003c/b\u003e","张光辉*","任宗萍"],"categories":null,"content":"","date":1354291200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"f049952f42cd221c9910fafb6a2c1d02","permalink":"http://zhulj.net/zh/publication/2012-stbctb-infiltrationmeasurecmp/","publishdate":"2012-12-01T00:00:00+08:00","relpermalink":"/zh/publication/2012-stbctb-infiltrationmeasurecmp/","section":"publication","summary":"入渗是土壤的基本物理性状,与降雨产流、侵蚀、非点源污染等过程密切相关,快速、准确测定土壤入渗速率具有重要的意义。以黄土高原沟壑区安塞水土保持综合试验站大豆地的黄土为测试土壤,利用双环、单环、圆盘入渗仪、Hood入渗仪4种方法测定了土壤入渗性能,并以双环法测定的稳渗速率、Hood仪测定的饱和导水率、单环/双环和圆盘测定的累积入渗量为基础,比较分析了4种方法各自的优劣。结果表明,单环、圆盘、Hood测定的稳渗速率分别为双环的116%、111%和225%,双环、单环、圆盘测定的饱和导水率分别为Hood的65.8%、75.1%和105%,双环、单环、圆盘达到稳渗时间分别为100、80和30 min。说明圆盘测得的稳渗速率、饱和导水率最接近标准值,而且省时省力省水,更适合于野外实验。","tags":["Experiments"],"title":"4种土壤入渗测定方法的比较","type":"publication"},{"authors":null,"categories":null,"content":" 1. 需求分析及解决思路 我们经常会想获取一些地点的经纬度坐标，比如北京市所有三甲医院列表及地址，如果对数据精度要求不高（不在意火星坐标的影响），使用百度地图API提供的返回坐标功能恰巧能满足这个需求。\n 调用百度地图JS版API，查询地点并将得到的经纬度坐标保存成CSV文件； 利用Python调用Arcpy将CSV文件中的经纬度转换成ESRI Shapefile。  2. 实现  程序是2011年11月写的，当时使用的是百度地图 API JS版 v1.2，我测试了一下，虽然历经版本迭代更新，这个代码依然可用。图1为运行效果。  图1 基于百度地图模糊查询地名并返回经纬度坐标\n完整代码如下，下载。\n 将坐标点CSV文件和以下代码放入同一个文件夹下，设置CSVName,XName和YName后运行即可得到ESRI Shapefile。  如果没有安装ArcGIS，即Arcpy不可用，可以选择调用GDAL，在此不再赘述。\n 运行示例点坐标下载，Python脚本下载\n#! /usr/bin/env python #coding=utf-8 ## Author : Liangjun Zhu ## Email : crazyzlj@gmail.com ## Date : 2015-1-23 ## Usage : Convert a .csv filetype points file to a vector shapefile ## put this .py file in the same folder, input the file name and ## x,y column name. import os,sys import arcpy from arcpy import env def currentPath(): path = sys.path[0] if os.path.isdir(path): return path elif os.path.isfile(path): return os.path.dirname(path) def CSV2PtsShp(CSVFile,X,Y): env.workspace = os.path.dirname(CSVFile) PtsShp = os.path.basename(CSVFile) PtsShp = PtsShp.split('.')[-2] + \u0026quot;.shp\u0026quot; print PtsShp try: arcpy.MakeXYEventLayer_management(CSVFile,X,Y,\u0026quot;tempLayer\u0026quot;,\u0026quot;\u0026quot;,\u0026quot;\u0026quot;) arcpy.CopyFeatures_management(\u0026quot;tempLayer\u0026quot;,PtsShp) except: print arcpy.GetMessages() arcpy.AddMessage(arcpy.GetMessages()) print os.path.dirname(CSVFile) print \u0026quot;%s Convert to Shp Done!\u0026quot; % CSVFile if __name__ == '__main__': CSVName = \u0026quot;designed_samples.csv\u0026quot; XName = \u0026quot;RecommendedX\u0026quot; YName = \u0026quot;RecommendedY\u0026quot; currFolder = currentPath() CSVFile = currFolder + os.sep + CSVName CSV2PtsShp(CSVFile,XName,YName)  ","date":1321056000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538317066,"objectID":"3d73876d7acb8a18a07e87e2f6a6e9ca","permalink":"http://zhulj.net/zh/post/2011-11-12-get-geographic-coordinates-of-given-place-based-on-baidumap-api/","publishdate":"2011-11-12T00:00:00Z","relpermalink":"/zh/post/2011-11-12-get-geographic-coordinates-of-given-place-based-on-baidumap-api/","section":"post","summary":"利用百度地图API查询指定城市地名坐标，并利用ArcPy生成矢量Shapefile文件。\n","tags":["Python"],"title":"基于百度地图API获取指定城市地名坐标并生成ESRI Shapefile","type":"post"}]